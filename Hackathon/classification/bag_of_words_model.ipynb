{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efe3037b-026b-4a5f-aa6f-78568a4d6419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Mina\n",
      "[nltk_data]     Fathi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ebdcc59-6116-4eab-81d7-894f4d9ec500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentences\n",
    "sent1 = \"Joe waited for the train, but the train was late.\"\n",
    "sent2 = \"Mary and Samantha took the bus.\"\n",
    "sent3 = \"I looked for Mary and Samantha at the bus station.\"\n",
    "sent4 = \"Mary and Samantha arrived at the bus station early.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29690d45-48ac-4e89-b3cc-fe043619134d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d5607f3-e191-4bff-a91e-552a1223f343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of all words in the sentences is: 19\n"
     ]
    }
   ],
   "source": [
    "# Finding the number of words in all sentences\n",
    "words = []\n",
    "for sent in (sent1, sent2, sent3, sent4):\n",
    "    words.extend([word.lower() for word in nltk.word_tokenize(sent) if word not in ['.', ',']])\n",
    "\n",
    "words = list(dict.fromkeys(words))\n",
    "print('Length of all words in the sentences is:', len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22696902-30c7-4f1d-9664-946b8067f614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All sentences in a list:\n",
      " ['Joe waited for the train, but the train was late.', 'Mary and Samantha took the bus.', 'I looked for Mary and Samantha at the bus station.', 'Mary and Samantha arrived at the bus station early.']\n"
     ]
    }
   ],
   "source": [
    "# put all sentences in an array\n",
    "all_sent = [sent1, sent2, sent3, sent4]\n",
    "print('All sentences in a list:\\n', all_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96699b98-04eb-4bd8-9e24-f9f7d4f1bf87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e264773-219d-4a8b-996c-054336027d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized sentences:\n",
      " [[0 0 0 1 1 0 0 0 0 0 2 1]\n",
      " [0 1 0 0 0 0 1 1 0 1 0 0]\n",
      " [0 1 0 0 0 1 1 1 1 0 0 0]\n",
      " [1 1 1 0 0 0 1 1 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Vectorizing the sentences\n",
    "cv = CountVectorizer(max_features=len(words), stop_words='english')\n",
    "vectorized_sent = cv.fit_transform(all_sent).toarray()\n",
    "print('Vectorized sentences:\\n', vectorized_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8deaae-7dac-4844-9001-afa4feb59147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
